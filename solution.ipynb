{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec40bd00",
   "metadata": {},
   "source": [
    "## Этап 1. Сбор и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "473da1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "загружаем и подготавливаем данные\n",
      "----------------------------------------\n",
      "загружено 1600498 строк из файла\n",
      "всего строк в файле: 1600498\n",
      "оставлено после сэмплирования: 320099 строк\n",
      "очищено текстов: 320099\n",
      "----------------------------------------\n",
      "\n",
      "примеры очистки:\n",
      "до:  @bkajino That awesome was for the walk, not the blisters\n",
      "после: that awesome was for the walk not the blisters\n",
      "\n",
      "----------------------------------------\n",
      "до:  @trent_reznor @mariqueen it makes me sad to see all the bs ppl are writing about and to you two.  I don't know why they can't let you be..\n",
      "после: it makes me sad to see all the bs ppl are writing about and to you two i don't know why they can't let you be\n",
      "\n",
      "----------------------------------------\n",
      "до:  i give up on them !\n",
      "после: i give up on them\n",
      "\n",
      "----------------------------------------\n",
      "до:  @jeanettejoy  Well said.  Never follow someone because of their name, follow because they have something worth listening too\n",
      "после: well said never follow someone because of their name follow because they have something worth listening too\n",
      "\n",
      "----------------------------------------\n",
      "до:  Working on 12 with @sherrisnack\n",
      "после: working on 12 with\n",
      "\n",
      "----------------------------------------\n",
      "после фильтрации по длине [4–16]: 198079 текстов\n",
      "средняя длина: 9.6 слов\n",
      "мин: 4, макс: 16\n",
      "----------------------------------------\n",
      "train: 158463\n",
      "val:   19808\n",
      "test:  19808\n",
      "----------------------------------------\n",
      "размер словаря: 61013\n",
      "примеры: 'love' -> 6870, 'the' -> 22408\n",
      "----------------------------------------\n",
      "создаём датасеты и даталоадеры\n",
      "----------------------------------------\n",
      "размер train_dataset: 1363329 пар (контекст → следующий токен)\n",
      "----------------------------------------\n",
      "пример из train_dataset[0]: input=tensor([    0,     0,     0,     0,     0,     0,     0,     0,     0, 39991]), target=15758\n",
      "----------------------------------------\n",
      "x_batch.shape: torch.Size([128, 10])  # [b, seq_len]\n",
      "y_batch.shape: torch.Size([128])  # [b]\n",
      "----------------------------------------\n",
      "сохраняем артефакты\n",
      "датасет готов, словарь сохранён\n"
     ]
    }
   ],
   "source": [
    "from src.data_utils import (\n",
    "    prepare_data,\n",
    "    create_data_loaders,\n",
    "    save_artifacts\n",
    ")\n",
    "\n",
    "# запуск подготовки\n",
    "train_texts, val_texts, test_texts, word_to_idx, idx_to_word, vocab_size, seq_len = prepare_data(\n",
    "    file_path='data/raw_data.csv',\n",
    "    sample_ratio=0.2,\n",
    "    min_len=4,\n",
    "    max_len=16,\n",
    "    seq_len=10,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# даталоадеры\n",
    "train_loader, val_loader, test_loader, train_dataset, val_dataset, test_dataset = create_data_loaders(\n",
    "    train_texts, val_texts, test_texts,\n",
    "    word_to_idx=word_to_idx,\n",
    "    seq_len=seq_len,\n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "# сохраняем\n",
    "save_artifacts(word_to_idx, idx_to_word, vocab_size, seq_len, train_dataset, val_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20ed40b",
   "metadata": {},
   "source": [
    "## Этап 2. Объявление модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e43ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "LSTMTokenizerModel(\n",
      "  (embedding): Embedding(61013, 128, padding_idx=0)\n",
      "  (lstm): LSTM(128, 256, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=61013, bias=True)\n",
      ")\n",
      "----------------------------------------\n",
      "размер словаря: 61013\n",
      "модель создана на устройстве: cuda\n",
      "количество параметров: 24,411,605\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from src.lstm_model import LSTMTokenizerModel\n",
    "\n",
    "# словарь\n",
    "with open('data/vocab_final.pkl', 'rb') as f:\n",
    "    vocab_data = pickle.load(f)\n",
    "\n",
    "# данные из словаря\n",
    "word_to_idx = vocab_data['word_to_idx']\n",
    "idx_to_word = vocab_data['idx_to_word']\n",
    "\n",
    "# параметры модели\n",
    "vocab_size = vocab_data['vocab_size']\n",
    "embed_dim = 128\n",
    "hidden_dim = 256\n",
    "num_layers = 2\n",
    "seq_len = vocab_data['seq_len'] \n",
    "\n",
    "# экземпляр модели\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTMTokenizerModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=embed_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=num_layers\n",
    ").to(device)\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(model)\n",
    "print(\"-\" * 40)\n",
    "print(f\"размер словаря: {vocab_size}\")\n",
    "print(f\"модель создана на устройстве: {device}\")\n",
    "print(f\"количество параметров: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6bc077",
   "metadata": {},
   "source": [
    "## Этап 3. Тренировка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd7842c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "словарь загружен: 61013 токенов\n",
      "пример: 'the' -> 22408\n",
      "длина контекста (seq_len): 10\n",
      "размер обучающей выборки: 1363329\n",
      "пример входа: (tensor([    0,     0,     0,     0,     0,     0,     0,     0,     0, 39991]), tensor(15758)) -> you\n",
      "используем устройство: cuda\n",
      "----------------------------------------\n",
      "\n",
      "дебаг: проверка данных\n",
      "----------------------------------------\n",
      "пример x_batch[0]: [0, 0, 0, 0, 35873, 7055, 29026, 19935, 59687, 48108]\n",
      "y_batch.min(): 42\n",
      "y_batch.max(): 60123\n",
      "forward и loss работают\n",
      "----------------------------------------\n",
      "фиксированный пример для сравнения каждую эпоху\n",
      "----------------------------------------\n",
      "контекст: thanks\n",
      "реальное продолжение: for\n",
      "ожидаем: thanks for\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 10652/10652 [02:57<00:00, 59.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | train loss: 74366.607 | val loss: 6.680 | val acc: 9.18% | val ppl: 796.33 | val rouge-l: 0.092\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: i\n",
      "топ-3: ['i', 'for', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 1 | lr: 5.00e-05 | val loss: 6.680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2: 100%|██████████| 10652/10652 [02:58<00:00, 59.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 | train loss: 68396.235 | val loss: 6.425 | val acc: 10.87% | val ppl: 617.17 | val rouge-l: 0.109\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'to', 'i']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 2 | lr: 5.00e-05 | val loss: 6.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3: 100%|██████████| 10652/10652 [02:57<00:00, 59.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 | train loss: 65864.592 | val loss: 6.281 | val acc: 12.13% | val ppl: 534.57 | val rouge-l: 0.122\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 3 | lr: 5.00e-05 | val loss: 6.281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4: 100%|██████████| 10652/10652 [02:57<00:00, 59.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 | train loss: 64173.955 | val loss: 6.186 | val acc: 12.91% | val ppl: 486.12 | val rouge-l: 0.129\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 4 | lr: 5.00e-05 | val loss: 6.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5: 100%|██████████| 10652/10652 [02:57<00:00, 59.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 | train loss: 62874.320 | val loss: 6.119 | val acc: 13.50% | val ppl: 454.18 | val rouge-l: 0.135\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 5 | lr: 5.00e-05 | val loss: 6.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6: 100%|██████████| 10652/10652 [02:58<00:00, 59.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 | train loss: 61812.793 | val loss: 6.070 | val acc: 13.95% | val ppl: 432.70 | val rouge-l: 0.140\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 6 | lr: 5.00e-05 | val loss: 6.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7: 100%|██████████| 10652/10652 [02:57<00:00, 59.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 | train loss: 60901.025 | val loss: 6.036 | val acc: 14.25% | val ppl: 418.20 | val rouge-l: 0.143\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 7 | lr: 5.00e-05 | val loss: 6.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8: 100%|██████████| 10652/10652 [02:57<00:00, 59.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 | train loss: 60068.393 | val loss: 6.006 | val acc: 14.61% | val ppl: 405.94 | val rouge-l: 0.147\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 8 | lr: 5.00e-05 | val loss: 6.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9: 100%|██████████| 10652/10652 [02:57<00:00, 59.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 | train loss: 59286.489 | val loss: 5.988 | val acc: 14.78% | val ppl: 398.51 | val rouge-l: 0.148\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 9 | lr: 5.00e-05 | val loss: 5.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10: 100%|██████████| 10652/10652 [02:57<00:00, 59.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 | train loss: 58588.774 | val loss: 5.971 | val acc: 15.06% | val ppl: 392.05 | val rouge-l: 0.151\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 10 | lr: 5.00e-05 | val loss: 5.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 11: 100%|██████████| 10652/10652 [02:57<00:00, 59.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 | train loss: 57960.587 | val loss: 5.956 | val acc: 15.29% | val ppl: 386.24 | val rouge-l: 0.153\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 11 | lr: 5.00e-05 | val loss: 5.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 12: 100%|██████████| 10652/10652 [02:57<00:00, 59.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 | train loss: 57366.967 | val loss: 5.948 | val acc: 15.42% | val ppl: 382.92 | val rouge-l: 0.155\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 12 | lr: 5.00e-05 | val loss: 5.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 13: 100%|██████████| 10652/10652 [02:57<00:00, 59.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 | train loss: 56860.605 | val loss: 5.945 | val acc: 15.60% | val ppl: 381.69 | val rouge-l: 0.156\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 13 | lr: 5.00e-05 | val loss: 5.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 14: 100%|██████████| 10652/10652 [02:57<00:00, 59.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 | train loss: 56381.638 | val loss: 5.935 | val acc: 15.72% | val ppl: 378.09 | val rouge-l: 0.158\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 14 | lr: 5.00e-05 | val loss: 5.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 15: 100%|██████████| 10652/10652 [02:57<00:00, 59.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 | train loss: 55862.951 | val loss: 5.935 | val acc: 15.79% | val ppl: 378.01 | val rouge-l: 0.158\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 15 | lr: 5.00e-05 | val loss: 5.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 16: 100%|██████████| 10652/10652 [02:57<00:00, 59.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 | train loss: 55339.905 | val loss: 5.939 | val acc: 15.90% | val ppl: 379.47 | val rouge-l: 0.159\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 16 | lr: 5.00e-05 | val loss: 5.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 17: 100%|██████████| 10652/10652 [02:57<00:00, 59.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 | train loss: 54835.304 | val loss: 5.936 | val acc: 16.06% | val ppl: 378.59 | val rouge-l: 0.161\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 17 | lr: 5.00e-05 | val loss: 5.936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 18: 100%|██████████| 10652/10652 [02:57<00:00, 59.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 | train loss: 54426.776 | val loss: 5.939 | val acc: 16.12% | val ppl: 379.63 | val rouge-l: 0.162\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 18 | lr: 2.50e-05 | val loss: 5.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 19: 100%|██████████| 10652/10652 [02:57<00:00, 59.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 | train loss: 53862.430 | val loss: 5.945 | val acc: 16.15% | val ppl: 382.00 | val rouge-l: 0.162\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 19 | lr: 2.50e-05 | val loss: 5.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 20: 100%|██████████| 10652/10652 [02:57<00:00, 59.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 | train loss: 53576.233 | val loss: 5.947 | val acc: 16.15% | val ppl: 382.48 | val rouge-l: 0.162\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 20 | lr: 2.50e-05 | val loss: 5.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 21: 100%|██████████| 10652/10652 [02:57<00:00, 59.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 | train loss: 53360.943 | val loss: 5.945 | val acc: 16.17% | val ppl: 381.78 | val rouge-l: 0.162\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "epoch 21 | lr: 2.50e-05 | val loss: 5.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 22: 100%|██████████| 10652/10652 [02:58<00:00, 59.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22 | train loss: 53168.690 | val loss: 5.948 | val acc: 16.23% | val ppl: 382.88 | val rouge-l: 0.163\n",
      "----------------------------------------\n",
      "прогресс модели (сравнение с истиной)\n",
      "----------------------------------------\n",
      "предсказание: for\n",
      "топ-3: ['for', 'i', 'to']\n",
      "реальность:   for\n",
      "----------------------------------------\n",
      "ранняя остановка на эпохе 22\n",
      "загружена лучшая модель\n",
      "----------------------------------------\n",
      "дополнительные метрики\n",
      "test loss: 5.928 | test acc: 15.88% | test ppl: 375.48 | test rouge-l: 0.159\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "сгенерированные примеры\n",
      "----------------------------------------\n",
      "→ i m so glad to see you in the sun is shining and i m back\n",
      "→ i love u when that was a great show i m sorry i love you too much\n",
      "→ today is an awesome day off to work tomorrow no one is coming here soon to\n",
      "→ life is going to be awesome and i feel like crap is in the hospital now\n",
      "→ i can't see my picture in the morning i don't want to be back to the house\n",
      "\n",
      "средняя длина сгенерированной фразы: 16.4 слов\n",
      "доля уникальных слов в генерации: 63.41%\n",
      "топ-5 слов в генерации: [('i', 8), ('to', 6), ('is', 5), ('the', 4), ('m', 3)]\n",
      "----------------------------------------\n",
      "количество обучаемых параметров: 24,411,605\n",
      "----------------------------------------\n",
      "генерация\n",
      "----------------------------------------\n",
      "i -> i miss my bestie so much to have you back in the uk and my mom\n",
      "i love -> i love my new baby too much more often but i don't want to go home i\n",
      "today -> today was a good day i feel like a bit better than i have to work\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "from src.lstm_model import generate\n",
    "from src.lstm_train import train \n",
    "from src.eval_lstm import evaluate_final\n",
    "\n",
    "# запуск обучения\n",
    "model, word_to_idx, idx_to_word, seq_len, device, test_loader = train()\n",
    "\n",
    "# финальная оценка\n",
    "evaluate_final(model, test_loader, word_to_idx, idx_to_word, seq_len, device)\n",
    "\n",
    "# примеры генерации\n",
    "print(\"-\" * 40)\n",
    "print(\"генерация\")\n",
    "print(\"-\" * 40)\n",
    "print('i ->', generate(model, 'i', word_to_idx, idx_to_word, seq_len, temperature=0.8, top_k=10))\n",
    "print('i love ->', generate(model, 'i love', word_to_idx, idx_to_word, seq_len, temperature=0.8, top_k=10))\n",
    "print('today ->', generate(model, 'today', word_to_idx, idx_to_word, seq_len, temperature=0.8, top_k=10))\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c524914c",
   "metadata": {},
   "source": [
    "## Этап 4. Использование предобученного трансформера distilgpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91bdd40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "загружаем модель distilgpt2\n",
      "используется GPU\n",
      "загружаем и подготавливаем данные\n",
      "загружено 1600498 твитов\n",
      "очищено текстов: 1600498\n",
      "отфильтровано текстов: 1251724\n",
      "валидационная выборка: 150 текстов\n",
      "----------------------------------------\n",
      "валидация модели\n",
      "----------------------------------------\n",
      "выполняем оценку модели на валидационной выборке\n",
      "\n",
      "----------------------------------------\n",
      "результаты валидации\n",
      "----------------------------------------\n",
      "метрика: ROUGE-L (точность предсказания следующего слова)\n",
      "количество оценок: 99\n",
      "средний ROUGE-L: 0.0976 ± 0.2930\n",
      "медиана ROUGE-L: 0.0000\n",
      "\n",
      "лучшие примеры предсказаний:\n",
      "----------------------------------------\n",
      "пример 1:\n",
      "контекст:    'what tragedy and disaster in'\n",
      "истинное:    'the'\n",
      "предсказанное: 'the'\n",
      "ROUGE-L:     1.0000\n",
      "\n",
      "пример 2:\n",
      "контекст:    'i miss him can't wait'\n",
      "истинное:    'to'\n",
      "предсказанное: 'to'\n",
      "ROUGE-L:     1.0000\n",
      "\n",
      "пример 3:\n",
      "контекст:    'has lost his ring it'\n",
      "истинное:    's'\n",
      "предсказанное: '’s'\n",
      "ROUGE-L:     1.0000\n",
      "\n",
      "пример 4:\n",
      "контекст:    'is fucked to go back'\n",
      "истинное:    'to'\n",
      "предсказанное: 'to'\n",
      "ROUGE-L:     1.0000\n",
      "\n",
      "пример 5:\n",
      "контекст:    'i m here friend and'\n",
      "истинное:    'i'\n",
      "предсказанное: 'I'\n",
      "ROUGE-L:     1.0000\n",
      "\n",
      "----------------------------------------\n",
      "генерация текстов\n",
      "----------------------------------------\n",
      "генерируем тексты на основе промптов\n",
      "----------------------------------------\n",
      "промпт 1:\n",
      "  вход:  i dived many times for the ball managed to save 50 the\n",
      "  выход: match.\n",
      "\n",
      "  полностью: i dived many times for the ball managed to save 50 the match.\n",
      "\n",
      "----------------------------------------\n",
      "промпт 2:\n",
      "  вход:  i just re pierced\n",
      "  выход: It’s all pretty awesome, but I don't think the real thing is how\n",
      "\n",
      "  полностью: i just re pierced.\n",
      "\n",
      "----------------------------------------\n",
      "промпт 3:\n",
      "  вход:  i couldn't bear to watch it and i thought the\n",
      "  выход: story was about a girl who lost her virginity.\n",
      "\n",
      "  полностью: i couldn't bear to watch it and i thought the story was about a girl who lost her virginity.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "генерация завершена\n"
     ]
    }
   ],
   "source": [
    "from src.eval_transformer_pipeline import TransformerModel\n",
    "\n",
    "# экземпляр модели\n",
    "model = TransformerModel()\n",
    "\n",
    "# данные\n",
    "test_texts, val_texts = model.prepare_data('data/raw_data.csv')\n",
    "\n",
    "# валидация модели\n",
    "avg_rouge, examples = model.validate_model(val_texts)\n",
    "\n",
    "# генерируем тексты\n",
    "generation_results = model.generate_texts(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fcb782",
   "metadata": {},
   "source": [
    "## Этап 5. Формулирование выводов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8a4b8d",
   "metadata": {},
   "source": [
    "\n",
    "> **Выводы:** Не могу дать однозначный ответ, что лучше. \n",
    "\n",
    "##### Начнём с метрик\n",
    "- Основная метрика по ТЗ, ROUGE, практически бесполезна для оценки distilgpt2, так как эта модель генерирует принципиально новые тексты, а не копирует фразы из эталона (и мы буквально берём из коробки готовый пайплайн, не проводя дообучение на своих данных). \n",
    "Для LSTM, которая часто работает ближе к шаблонному предсказанию, ROUGE ещё может иметь некоторый смысл.\n",
    "- Что касается других метрик, таких как accuracy или perplexity, их использование также некорректно для сравнения, так как мы опять же берём \"из коробки\" distilgpt2, нам нам ни логиты, ни вероятности не дадут \n",
    "(Измерить вроде можно, но скорее бессмысленно (метрики accuracy и perplexity предназначены для оценки языковых моделей на задачах предсказания следующего слова и плохо подходят для оценки качества генерации текста), чем сложно + вручную уже запускала distilgpt2, слишком запарно для данной задачи)\n",
    "\n",
    "##### Основной акцент в сравнении приходится делать на анализ примеров генерации и технические характеристики\n",
    "Поэтому, выбираем:\n",
    "- LSTM, если приоритетом является вычислительная эффективность модели, а не качество текста (жёсткие аппаратные ограничения, например, чат-бот с очень узкой тематикой, мне представляется мобильная игра, в которой чат-бот должен следовать только своему лору (LOR'у, ограниченному набору правил и контекста) и словарь не особо большой).\n",
    "- distilgpt2, если приоритетом является связность (человекочитаемость) и разнообразие генерируемого текста (диалоговые системы, автоматическое дополнение текста, вывод инструкций по узкой тематике, чат-бот для работников компании, не крупной, при больших данных те же x5 используют не лёгкие модели, а берут API OpenAI, например).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8df00da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "загружаем LSTM модель\n",
      "----------------------------------------\n",
      "загружаем distilgpt2 модель\n",
      "загружаем модель distilgpt2\n",
      "используется GPU\n",
      "----------------------------------------\n",
      "сравнение генераций\n",
      "----------------------------------------\n",
      "\n",
      "пример 1:\n",
      "промпт: 'i love to play with my'\n",
      "----------------------------------------\n",
      "lstm:      i love to play with my favorite babies and comment when i have anything jet meka if no legal either is\n",
      "distilgpt2: i love to play with my friends.\n",
      "\n",
      "\n",
      "If you would like to see a video for my next book, please visit\n",
      "----------------------------------------\n",
      "\n",
      "пример 2:\n",
      "промпт: 'today is a beautiful day for'\n",
      "----------------------------------------\n",
      "lstm:      today is a beautiful day for it hahaha sits it sucks i have went on what to do fresh address long\n",
      "distilgpt2: today is a beautiful day for all of us, and for all of you.”\n",
      "\n",
      "\n",
      "In addition to the holiday\n",
      "----------------------------------------\n",
      "\n",
      "пример 3:\n",
      "промпт: 't can't believe how fast time'\n",
      "----------------------------------------\n",
      "lstm:      t can't believe how fast time for something now like i ll study there in a while my friend hateeee i\n",
      "distilgpt2: t can't believe how fast time is going to get through the game.\n",
      "----------------------------------------\n",
      "\n",
      "пример 4:\n",
      "промпт: 'you should try this amazing'\n",
      "----------------------------------------\n",
      "lstm:      you should try this amazing and billy mga we sucky i seem to do something sometime hahaha you get thinking of\n",
      "distilgpt2: you should try this amazing book!\n",
      "\n",
      "\n",
      "This is the perfect book for a young man.\n",
      "If you want to\n",
      "----------------------------------------\n",
      "\n",
      "пример 5:\n",
      "промпт: 'we are going to the'\n",
      "----------------------------------------\n",
      "lstm:      we are going to the maid times on secret bad collection is having a great weekend prefect lovely day for b\n",
      "distilgpt2: we are going to the next phase,” she said. “It” will be a new era for the\n",
      "----------------------------------------\n",
      "\n",
      "пример 6:\n",
      "промпт: 'the weather is really nice'\n",
      "----------------------------------------\n",
      "lstm:      the weather is really nice to be home to work tweeting soon grade whirring curious m fans today av amazing stack\n",
      "distilgpt2: the weather is really nice, and there's just too much snow.\n",
      "\n",
      "\n",
      "Here's a few things you should know\n",
      "----------------------------------------\n",
      "\n",
      "пример 7:\n",
      "промпт: 'i think we should go to'\n",
      "----------------------------------------\n",
      "lstm:      i think we should go to holland though it didn't do a flat for me when she s having serious sooner\n",
      "distilgpt2: i think we should go to the World Cup, we're not going to make the same mistakes as we did. I think we\n",
      "----------------------------------------\n",
      "\n",
      "пример 8:\n",
      "промпт: 'this is the best movie I'\n",
      "----------------------------------------\n",
      "lstm:      this is the best movie I onto the use conversations because me a twinkie shout in my bestest inspite i see\n",
      "distilgpt2: this is the best movie I've ever seen!\n",
      "----------------------------------------\n",
      "\n",
      "пример 9:\n",
      "промпт: 'she always knows how to make'\n",
      "----------------------------------------\n",
      "lstm:      she always knows how to make a mistake retweet lmao 3 boii or give up reading yourself goin health t envelopes\n",
      "distilgpt2: she always knows how to make a good impression.\n",
      "----------------------------------------\n",
      "\n",
      "пример 10:\n",
      "промпт: 'life is too short to'\n",
      "----------------------------------------\n",
      "lstm:      life is too short to go i think im in the office lobster them might do the first runner out better\n",
      "distilgpt2: life is too short to take this seriously. I will try to keep this as a point to remind people about the importance of\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "интерактивная генерация\n",
      "----------------------------------------\n",
      "\n",
      "промпт: 'it's the best day of'\n",
      "----------------------------------------\n",
      "lstm:      it's the best day of few weeks i am avail out arghh up ugh had my shit account going well such\n",
      "distilgpt2: it's the best day of the year.\"\n",
      "----------------------------------------\n",
      "\n",
      "завершено\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import pickle\n",
    "from src.lstm_model import LSTMTokenizerModel, generate\n",
    "from src.eval_transformer_pipeline import TransformerModel\n",
    "\n",
    "# загрузка lstm\n",
    "print(\"загружаем LSTM модель\")\n",
    "with open('data/vocab_final.pkl', 'rb') as f:\n",
    "    vocab_data = pickle.load(f)\n",
    "\n",
    "word_to_idx = vocab_data['word_to_idx']\n",
    "idx_to_word = vocab_data['idx_to_word']\n",
    "seq_len = vocab_data['seq_len']\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lstm_model = LSTMTokenizerModel(len(word_to_idx)).to(device)\n",
    "lstm_model.load_state_dict(torch.load('models/best_lstm_model_final.pt', map_location=device))\n",
    "lstm_model.eval()\n",
    "\n",
    "# загрузка distilgpt2 модели\n",
    "print(\"-\" * 40)\n",
    "print(\"загружаем distilgpt2 модель\")\n",
    "gpt2_model = TransformerModel()\n",
    "gpt2_generator = gpt2_model.generator\n",
    "\n",
    "# 10 примеров для генерации\n",
    "test_examples = [\n",
    "    \"i love to play with my\",\n",
    "    \"today is a beautiful day for\",\n",
    "    \"t can't believe how fast time\",\n",
    "    \"you should try this amazing\",\n",
    "    \"we are going to the\",\n",
    "    \"the weather is really nice\",\n",
    "    \"i think we should go to\",\n",
    "    \"this is the best movie I\",\n",
    "    \"she always knows how to make\",\n",
    "    \"life is too short to\"\n",
    "]\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"сравнение генераций\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# генерация для тестовых примеров\n",
    "for i, prompt in enumerate(test_examples, 1):\n",
    "    print(f\"\\nпример {i}:\")\n",
    "    print(f\"промпт: '{prompt}'\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # генерация lstm\n",
    "    lstm_output = generate(lstm_model, prompt, word_to_idx, idx_to_word, seq_len, max_len=20)\n",
    "    print(f\"lstm:      {lstm_output}\")\n",
    "    \n",
    "    # генерация distilgpt2\n",
    "    try:\n",
    "        gpt2_result = gpt2_generator(\n",
    "            prompt,\n",
    "            max_new_tokens=20,\n",
    "            do_sample=True,\n",
    "            temperature=0.8,\n",
    "            top_p=0.9,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=gpt2_generator.tokenizer.eos_token_id\n",
    "        )\n",
    "        gpt2_output = gpt2_result[0]['generated_text'].strip()\n",
    "        print(f\"distilgpt2: {gpt2_output}\")\n",
    "    except Exception as e:\n",
    "        print(f\"distilgpt2: ошибка генерации - {e}\")\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# интерактивный ввод промпта\n",
    "print(\"-\" * 40)\n",
    "print(\"интерактивная генерация\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "while True:\n",
    "    user_prompt = input(\"\\nвведите свой промпт (или 'exit' для выхода): \")\n",
    "    \n",
    "    if user_prompt.lower() == 'exit':\n",
    "        break\n",
    "    \n",
    "    if not user_prompt.strip():\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nпромпт: '{user_prompt}'\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # генерация lstm\n",
    "    try:\n",
    "        lstm_output = generate(lstm_model, user_prompt, word_to_idx, idx_to_word, seq_len, max_len=20)\n",
    "        print(f\"lstm:      {lstm_output}\")\n",
    "    except Exception as e:\n",
    "        print(f\"lstm: ошибка генерации - {e}\")\n",
    "    \n",
    "    # генерация distilgpt2\n",
    "    try:\n",
    "        gpt2_result = gpt2_generator(\n",
    "            user_prompt,\n",
    "            max_new_tokens=30,\n",
    "            do_sample=True,\n",
    "            temperature=0.8,\n",
    "            top_p=0.9,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=gpt2_generator.tokenizer.eos_token_id\n",
    "        )\n",
    "        gpt2_output = gpt2_result[0]['generated_text'].strip()\n",
    "        print(f\"distilgpt2: {gpt2_output}\")\n",
    "    except Exception as e:\n",
    "        print(f\"distilgpt2: ошибка генерации - {e}\")\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"\\nзавершено\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
